{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition Based Approaches to Time Series Forecasting: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Experience with the specific topic: Novice.  \n",
    "Professional experience: Some industry experience.\n",
    "\n",
    "Some familiarity with the basic concepts of Time Series forecasting concepts will allow the reader to better follow this tutorial, although advanced knowledge is not required. For a good introduction to the basic concepts of forecasting, see [this tutorial](https://www.datascience.com/blog/time-series-forecasting-machine-learning-differences) and [this tutorial](https://www.datascience.com/blog/introduction-to-forecasting-with-arima-in-r-learn-data-science-tutorials). \n",
    "\n",
    "To follow the example, the reader should also be familiar with basic R syntax. R packages needed: forecast, prophet, bsts, ggplot2, and repr.The sample dataset can be downloaded here. \n",
    "\n",
    "## Introduction \n",
    "\n",
    "In this overview, we would like to introduce decomposition based approaches to time series forecasting. Decompostion based methods are a simple but robust approach to modelling and forecasting time series data. \n",
    "The basic idea behind such methods are that they explicitly model the data as a combination of trend, seasonal and remainder components, as opposed to trying to capture temporal dependancies and auto-correlations in the data the way ARIMA or GARCH models do. \n",
    "\n",
    "Decomposing a time series model invloves splitting it into 3 or 4 components, in the form of: \n",
    "\n",
    "$ \\hat{Y}(t) = T(t) + S(t) + R(t) + \\epsilon(t) $    *(note that this is an additive decompostion, we will deal with the multiplicative case later)*. \n",
    "\n",
    "With:   \n",
    "$ \\hat{Y}(t) $  : The modelled/forecast value at time $t$  \n",
    "$ T(t) $  : The trend component at time $t$  \n",
    "$ S(t) $  : The seasonal component at time $t$  \n",
    "$ R(t) $ : The Remainder at time $t$  \n",
    "$ \\epsilon(t) $ : Error term \n",
    "\n",
    "Time series decomposition is usually presented as an analysis step to be perfromed before generating predictions, but it can also be used as a forecasting method in and of itself, if you know before hand what the structure of your time series will look like. Such scenarios occur frequently in a business context, for example in retail demand forecasting, where for some products, it is safe to assume before hand that you sales data will have a yearly seasonal pattern and a year over year trend. \n",
    "\n",
    "To forecast a time series using a decomposition model, you calculate the future values for each seperate component and then add them back together to obtain a prediction. The challenge then simply becomes finding the best model for each of the components.\n",
    "\n",
    "In the following overview, we will present 3 approaches to forecasting using decompostion with R: Seasonal Trend decompostion using LOESS, Bayesian Structural Time Series, and Facebook Prophet. \n",
    "\n",
    "First, we will decompose the Air Passengers time series and forecast it using each of the 3 methods. Then we will work on improving the accuracy of the forecasts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the required libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the required libraries \n",
    "library(ggplot2)\n",
    "library(forecast)\n",
    "library(bsts)\n",
    "library(prophet)\n",
    "library(repr)\n",
    "\n",
    "#Choosing a theme for clear and consistent data plots \n",
    "theme_set(theme_bw()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the data \n",
    "We will use the air plane passengers data set which is a classic data set for benchmarking time series models first introduced by Box and Jenkins in 1976 (It is to time series forecasting what [the Iris data](https://en.wikipedia.org/wiki/Iris_flower_data_set) set is to classifcation and regression algorithms). In particular the Air Passenger time series has a very clear trend and seasonal pattern  and so is perfect for testing decompostion methods.\n",
    "This data set is avalailble as part of the base R data package - but it can also be downloaded from [here](https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&display=line) (in that case you would have to use something like `read.csv()` to load the data and format it as a time series object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the airpassengers data \n",
    "data(\"AirPassengers\") \n",
    "plot(AirPassengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the data into test and train \n",
    "train <- window(AirPassengers, end = c(1958, 12))\n",
    "test <- window(AirPassengers, start = c(1959, 1), end = c(1960,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Decompostion and Forecasting\n",
    "\n",
    "### 3.1 Seasonal Trend decompostion using LOESS (STL) \n",
    "\n",
    "The STL was roposed by Cleveland et *al.* in 1990. STL uses the [LOESS (**LO**cal regr**ESS**ion) method](https://en.wikipedia.org/wiki/Local_regression) to model the trend and seasonal components using polynomial regression. The algorithm works by running two loops: \n",
    "- An outer loop were robustness coeifficients are calcualted to minimize the effect of outliers.\n",
    "- An inner loop were the trend component and seasonal component are iteratively updated using LOESS smoothing. \n",
    "\n",
    "The algorithm can be set to run for a fixed number of iterations for each loop, or it can be set to run until a specific convergence criterion is met (in the R versions of STL presented here, we will use the default number of fixed iterations which is 2). In addition, we can specify to STL whether we want the seasonal component to remain constant over time or whether we want to change (in R this can be specified using the paramter `s.window`).\n",
    "\n",
    "To forecast with STL, we first use STL to decompose the time series into 3 components:  \n",
    "$ \\hat{Y}(t) = T(t) + S(t) + R(t) $  \n",
    "\n",
    "We then apply a standard forecasting algorithm to the remainder $R(t)$, such as ARIMA or Exponential Smoothing, and generate an h-step ahead forecast for the remainder component $R(t+h)$.\n",
    "\n",
    "Lastly we calculate the h-step ahead trend component $T(t+h)$ and $S(t+h)$ and sum all three components to obtain a final forecast. \n",
    "\n",
    "If we want ot use STL for analysis only, then the `STL()` function that comes with the base R installation is sufficient. To use STL for forecasting however, it is easier to use the `STLF()` in the Forecast package, which uses the original `STL()` function for decomposition but also allows us to specify which algorithm to use for forecasting the remainder. \n",
    "\n",
    "To perform an STL decomposition, you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decompose the time series \n",
    "AirPassengersSTL <- stl(AirPassengers, s.window=\"periodic\", robust=TRUE)\n",
    "plot(AirPassengersSTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you don't need to pass a number of seasons to the STL() function, it is picking it up from the frequency that is defined in the original time series object `AirPassengers`.\n",
    "\n",
    "To generate forecasts, you can use `STLF()`, which allows you to specify which algorithm to use for forecasting the remainder. In this case we will use ARIMA, we don't need to specify the ARIMA orders (p,q,d) - the forecast method will find the optimal orders on its own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the STL model, using ARIMA to forecast the remainder \n",
    "AirPassengersSTL_ARIMA <- stlf(train, method=\"arima\")\n",
    "#Plot the results\n",
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "autoplot(train , ylab = 'Passengers') + scale_x_yearmon() + autolayer(test, series=\"Test Data\") +\n",
    "  autolayer(ts(AirPassengersSTL_ARIMA$mean,frequency=12, start=c(1959,1)), series=\"STL + ARIMA Forecasts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Bayesian Structural Time Series \n",
    "\n",
    "\n",
    "Proposed by Scott and Varian in 2013, Bayesian Structural Time Series are a powerful set of methods that cover a large class of time series models using the [State Space representation](https://en.wikipedia.org/wiki/State-space_representation) of time series and Bayesian statistics. \n",
    "\n",
    "In the State Space approach, a time series can be written as a set of two equations, a state equation describing the overal evolution of the system in terms of unobserved states, and an observation or measurment euqation describing the relationship between the observable variables and the hidden states. \n",
    "\n",
    "$\\alpha(t+1) = T(t) \\, \\alpha(t) + R(t)\\, \\eta(t)$ :   The state equation, with $\\alpha(t)$ the state of the system at time $t$.  \n",
    "$\\hat{Y}(t) = Z^T(t)\\,  \\alpha(t) + \\epsilon(t) $ :   The observation equation relating the values of the time series to the hidden states. \n",
    "\n",
    "\n",
    "It is straightforward to rewrite the trend and seasonal decompostion of a time series:\n",
    "\n",
    "\n",
    "$\\hat{Y}(t) = T(t) + S(t) + \\epsilon(t) $ \n",
    "\n",
    "(A BSTS model can also include a set of external regressors $\\beta \\, X(t)$, although we don't so so here) \n",
    "\n",
    "In state space form: \n",
    "\n",
    "\n",
    "$\\hat{Y}(t) = Z^T(t) \\,  \\alpha(t) + \\epsilon(t) $ \n",
    "\n",
    "With:  \n",
    "\n",
    "$\\alpha(t) = \\begin{bmatrix} \n",
    "    T(t) \\\\\n",
    "    S(t) \n",
    "    \\end{bmatrix} $ \n",
    "    \n",
    "and $Z(t) = [1 \\: 1]$  \n",
    "\n",
    "And the state equation is: \n",
    "\n",
    "$ T(t) = T(t-1) + u(t) $  \n",
    "$ S(t) = - \\sum_{i= 1}^{N - 1}{S(t-i)} + w(t) $ (with $S(t-i)$ a set of seasonal dummy variables used to model seasonality). (i.e $\\eta(t) = u(t) + w(t)$). \n",
    "\n",
    "[Kalman filtering](https://en.wikipedia.org/wiki/Kalman_filter) and an [MCMC algorithm](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo) are used to fit the model. Forecast are then calculated from the posterior predictive distribution.  \n",
    "\n",
    "Let's fit a BSTS model on our data and then plot the components: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the BSTS model \n",
    "Trend_Seasonal_states <- AddSemilocalLinearTrend(list(),train)\n",
    "Trend_Seasonal_states <- AddSeasonal(Trend_Seasonal_states,train, nseasons = 12)\n",
    "AirPassengersBSTS <- bsts(train,state.specification = Trend_Seasonal_states, niter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=4)\n",
    "plot(AirPassengersBSTS)\n",
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "plot(AirPassengersBSTS, \"components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To generate forecasts and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSTSForecasts <- predict.bsts(AirPassengersBSTS, horizon = 24)\n",
    "BSTSForecastsFormatted <- ts(BSTSForecasts$mean,frequency=12, start=c(1959,1))\n",
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "autoplot(train , ylab = 'Passengers') + scale_x_yearmon() + autolayer(test, series=\"Test Data\") +\n",
    "  autolayer(BSTSForecastsFormatted, series=\"BSTS Forecasts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Facebook Prophet \n",
    "\n",
    "Prophet is a forecasting method developped at Facebook, which they open sourced in 2017. It is essentially a curve fitting approach, very similar in spirit to how BSTS models trend and seasonality, except that it uses [Generalized Additive Models](https://en.wikipedia.org/wiki/Generalized_additive_model) instead of a State Space representation to describe each component. \n",
    "\n",
    "Similar to the other 2 approaches, a basic prophet model is written as: \n",
    "\n",
    "$\\hat{Y}(t) = T(t) + S(t) + H(t) + \\epsilon(t) $ \n",
    "\n",
    "with $T(t)$ the trend, $S(T)$ the seasonality and $H(T)$ an additional component to represent Holiday effects. \n",
    "\n",
    "The rend is modelled either as a logistic growth model for time series with saturated growth: \n",
    "\n",
    "$T(t) = \\frac{C}{1 + exp(-k(t))}$ with $C$ the capacity of the model (i.e. maximum level of the time series). \n",
    "\n",
    "Or a piece-wise linear growth model for unbounded growths:  \n",
    "\n",
    "$T(t) = kt $\n",
    "\n",
    "Changes in trend are modelled using changepoints in the growth rate $k$. \n",
    "\n",
    "The seasonal component is modelled using a Fourier series: \n",
    "\n",
    "$S(t) = \\sum_{n=1}^{N}{(a_n cos(\\frac{2\\pi nt}{P}) + b_n cos(\\frac{2\\pi nt}{P}))}$ with $P$ the period of the time series (365 days for yearly data, 7 days for weekly data, etc...) and $a$ and $b$ are models to be estimating. \n",
    "\n",
    "The holdiay component $H(t)$ is modelled as a regression on the specific holiday dates (which would have to be provided seperately - although we won't cover that here). \n",
    "\n",
    "The [L-BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS) agorithm is ued to fit the model. \n",
    "\n",
    "Facebook Prophet works great out if the box and is very intuitive, especially for non specialists with no time series or data science training, but it has very rigid requirements in the way the data should be formated. The time series data needs to be passed to the function as dataframe with a column 'ds' for date and 'y' for data. \n",
    "\n",
    "So the first step in training a Prophet model will to be format the data properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a data frame in the right format for Prophet\n",
    "FBTrain <- data.frame(ds = as.Date(as.yearmon(time(train))), y=as.matrix(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a Propbhet model to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a model and then generate forecasts \n",
    "m <- prophet(FBTrain,yearly.seasonality=TRUE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet also requires that a future time dataframe be defined, before generating forecasts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "future <- make_future_dataframe(m, periods = 24, freq = 'month')\n",
    "forecast <- predict(m, future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the components \n",
    "options(repr.plot.width=4, repr.plot.height=4)\n",
    "prophet_plot_components(m,forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally you can plot the forecasts. Note that Prophet comes with it's own plotting function, but we will be using `autoplot` from the forecast package so as to keep our plots consistent: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the results \n",
    "ProphetForecast <- ts(forecast$yhat,frequency=12, start=c(1949,1))\n",
    "ProphetForecast <- window(ProphetForecast, start = c(1959, 1), end = c(1960,12))\n",
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "autoplot(train , ylab = 'Passengers') + scale_x_yearmon() + autolayer(test, series=\"Test Data\") +\n",
    "  autolayer(ProphetForecast, series=\"Prophet Forecasts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improving Accuracy \n",
    "\n",
    "The forecasts that we have generated so far using these three approaches are \"OK\" - they seem to follow the general trend of the time series and they also replicated the seasonal patter in the data. But they still seem to fail to capture the increase in the magnitude of the seasonal variation over time. This because the Air Passengers time series has more of a multiplicative seasonal pattern than an additive one. In the next section we will try to overcome this difficulty by applying a log transform to the data so that multiplicative seasonality can be represented by an additive model. We will rerun each of the forecasting methods on the log transformed data, and then reverse transform the resulting forecats and compare them to the original data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the log transformed data - you can see that the seasonality is more additive now. \n",
    "options(repr.plot.width=6, repr.plot.height=4)\n",
    "plot(log10(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 STL with log transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AirPassengersSTL_ARIMA_log <- stlf(log10(train),method=\"arima\")\n",
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "autoplot(train , ylab = 'Passengers') + scale_x_yearmon() + autolayer(test, series=\"Test Data\") +\n",
    "  autolayer(ts(10^as.numeric(AirPassengersSTL_ARIMA_log$mean),frequency=12, start=c(1959,1)), series=\"STL + log Forecasts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 BSTS with log transfromed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the BSTS model \n",
    "Trend_Seasonal_states_log <- AddGeneralizedLocalLinearTrend(list(),log10(train))\n",
    "Trend_Seasonal_states_log <- AddSeasonal(Trend_Seasonal_states_log,train,nseasons=12)\n",
    "AirPassengersBSTS_log <- bsts(log10(train),state.specification = Trend_Seasonal_states_log, niter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSTSForecasts_log <- predict.bsts(AirPassengersBSTS_log, horizon = 24, quantiles = c(0.0000001, 0.000001))\n",
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "autoplot(train , ylab = 'Passengers') + scale_x_yearmon() + autolayer(test, series=\"Test Data\") +\n",
    "  autolayer(ts(10^as.numeric(BSTSForecasts_log$mean),frequency=12, start=c(1959,1)), series=\"BSTS + log Forecasts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Prophet with log transfromed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a data frame in the right format for Prophet\n",
    "FBTrain_log <- data.frame(ds = as.Date(as.yearmon(time(train))), y=as.matrix(log10(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a model and then generate forecasts \n",
    "m <- prophet(FBTrain_log,yearly.seasonality=TRUE , seasonality.prior.scale = 2) \n",
    "future <- make_future_dataframe(m, periods = 24, freq = 'month')\n",
    "forecast <- predict(m, future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProphetForecast <- ts(10^as.numeric(forecast$yhat),frequency=12, start=c(1949,1))\n",
    "ProphetForecast <- window(ProphetForecast, start = c(1959, 1), end = c(1960,12))\n",
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "autoplot(train , ylab = 'Passengers') + scale_x_yearmon() + autolayer(test, series=\"Test Data\") +\n",
    "  autolayer(ProphetForecast, series=\"Prophet Forecasts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In all 3 cases, we can see that using the log transform improved the accuracy of the forecasts for all three methos, although BSTS seems to perfrom better than the other two methods. \n",
    "\n",
    "## 5 Some notes:  \n",
    "\n",
    "- We didn't mention forecast intervals in this overview, we only generated point forecasts. In many business scenarios, such as demand forecasting and supply chain planning, the forecast intervals are just as important as the point forecasts. Each of the R functions used allows you to generate forecast intervals as well.  \n",
    "\n",
    "- We informaly evaluated the performance of the forecast methods based on plots of forecasts vs actuals for hold out test data. A more rigourous analysis of these methods perfroamce would require the calculation of forecast error metrics like MAPE and RMSE. \n",
    "\n",
    "- In the Air Passengers data set, there is only one yearly seasonal component. But several business time series can have multiple seasonalities. For example a restaurant customer time series will have daily seasonality (with peakes at lunch time and dinner time) and weekly seasonality (less customers on weekends). STL cannot handle more than one seasonal component. Prophet can handle multiple seasonalities, although as mentioned above it requires specific date formats. BSTS can hanle multiple seasonalities by using a Fourier series (the same way as prophet) for representing the seasonal component, (Call `AddTrig` instead of `AddSeasonal`).   \n",
    "\n",
    "- STL in its basic form doesn't allow for hoiday effects, although the version of STL that is available in R Forecast package can take in holidays as exogenous variables input into the forecast method that is used for modelling the remainder. \n",
    "\n",
    "- Prophet and BSTS can both handle holiday effects. In Prophet this is explicit and all you need to do is provide a dataframe with the holiday dates. In BSTS you need to model the holidays as a set of external regressors.   \n",
    "\n",
    "- BSTS full potential is realized when we add additional data beyond the time series and holiday data. For example, for the Air Passenger data, we could add additional factors such as economic conditions, Airline marketing data, number of internet queries for air plane trips, etc...and then Bayesian modelling can be used to improve the accuracy of the forecats. In particular, BSTS is very useful for \"Nowcasting\" - predicting the values of time series in the present. In the Air Passenger data example, it would take several months for the air lines to compile and release the data, so you can't know the value for the current month untill several months into the future. If however you needed to forecast the number of air passengers for the current month, and you couldn't afford to wait, you could use the above mentioned external data along with historical values of the air passenger traffic and \"nowcast\" the number of air passengers for the current month.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Conclusion: \n",
    "\n",
    "In this overview, we introduced 3 decompostion based approaches to forecasting, and showed how they can be used as simple, easily interpratable, but also robust, methods for univariate time series forecasting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References: \n",
    "- Cleveland et *al.*, \"STL: A Seasonal-Trend Decomposition\", 1990 \n",
    "- Scott & Varian, \"Predicting the present with Bayesian structural time series\", (2013).  \n",
    "- Taylor & Letham,  \"Forecasting at scale\", 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
